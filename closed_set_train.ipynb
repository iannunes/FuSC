{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ff609c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import random\n",
    "import time\n",
    "import gc\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import scipy.spatial.distance as spd\n",
    "\n",
    "from skimage import io\n",
    "from skimage import util\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from torch.backends import cudnn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from base import *\n",
    "from models import *\n",
    "from utils import check_mkdir, evaluate, AverageMeter, CrossEntropyLoss2d, LovaszLoss, FocalLoss2d\n",
    "\n",
    "import copy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60557d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden: 0\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "############################################\n",
    "Vaihingen/Potsdam classes:\n",
    "    0 = Street\n",
    "    1 = Building\n",
    "    2 = Grass\n",
    "    3 = Tree\n",
    "    4 = Car\n",
    "    5 = Surfaces\n",
    "    6 = Boundaries\n",
    "############################################\n",
    "\n",
    "############################################\n",
    "iSAID classes:\n",
    "     0 = Background\n",
    "     1 = Ship\n",
    "     2 = Small Vehicle\n",
    "     3 = Helicopter\n",
    "     4 = Swimming Pool\n",
    "     5 = Baseball Court\n",
    "     6 = Storage Tank\n",
    "     7 = Tennis Court\n",
    "     8 = Basketball Court\n",
    "     9 = Ground Track Field\n",
    "    10 = Harbor\n",
    "    11 = Bridge\n",
    "    12 = Large Vehicle\n",
    "    13 = Soccerball Field\n",
    "    14 = Plane\n",
    "    15 = Roundabout\n",
    "############################################\n",
    "\n",
    "############################################\n",
    "GRSS classes:\n",
    "     0 = Unclassified\n",
    "     1 = Healthy grass\n",
    "     2 = Stressed grass\n",
    "     3 = Artificial turf\n",
    "     4 = Evergreen trees\n",
    "     5 = Deciduous trees\n",
    "     6 = Bare earth\n",
    "     7 = Water\n",
    "     8 = Residential buildings\n",
    "     9 = Non-residential buildings\n",
    "    10 = Roads\n",
    "    11 = Sidewalks\n",
    "    12 = Crosswalks\n",
    "    13 = Major thoroughfares\n",
    "    14 = Highways\n",
    "    15 = Railways\n",
    "    16 = Paved parking lots\n",
    "    17 = Unpaved parking lots\n",
    "    18 = Cars\n",
    "    19 = Trains\n",
    "    20 = Stadium seats\n",
    "############################################\n",
    "'''\n",
    "\n",
    "# Predefining directories.\n",
    "ckpt_path = './ckpt'\n",
    "outp_path = './outputs'\n",
    "\n",
    "# Setting predefined arguments.\n",
    "args = {\n",
    "    'epoch_num': 1200,            # Number of epochs.\n",
    "    'lr': 1e-3,                   # Learning rate.\n",
    "    'weight_decay': 5e-6,         # L2 penalty.\n",
    "    'momentum': 0.9,              # Momentum.\n",
    "    'batch_size': 1,              # Batch size.\n",
    "    'num_workers': 4,             # Number of workers on data loader.\n",
    "    'print_freq': 1,              # Printing frequency for mini-batch loss.\n",
    "    'w_size': 224,                # Width size for image resizing.\n",
    "    'h_size': 224,                # Height size for image resizing.\n",
    "    'test_freq': 1,               # Test each test_freq epochs.\n",
    "    'save_freq': 1200,            # Save model each save_freq epochs.\n",
    "    'input_channels': 4,          # Number of input channels in samples/DNN.\n",
    "    'num_classes': 5,             # Number of original output classes in dataset.\n",
    "}\n",
    "\n",
    "# Reading system parameters.\n",
    "conv_name = 'unet'\n",
    "args['hidden_classes'] = '0'\n",
    "print('hidden: ' + args['hidden_classes'])\n",
    "\n",
    "dataset_name = 'Vaihingen'\n",
    "\n",
    "if dataset_name == 'Potsdam':\n",
    "    \n",
    "    args['epoch_num'] = 600\n",
    "    args['test_freq'] = args['test_freq']\n",
    "    args['save_freq'] = args['save_freq']\n",
    "    args['num_workers'] = 0\n",
    "    \n",
    "hidden = []\n",
    "if '_' in args['hidden_classes']:\n",
    "    hidden = [int(h) for h in args['hidden_classes'].split('_')]\n",
    "else:\n",
    "    hidden = [int(args['hidden_classes'])]\n",
    "    \n",
    "num_known_classes = args['num_classes'] - len(hidden)\n",
    "num_unknown_classes = len(hidden)\n",
    "\n",
    "\n",
    "weights = []\n",
    "if dataset_name == 'iSAID':\n",
    "    if 0 not in hidden:\n",
    "        weights = [100.0 for i in range(num_known_classes)]\n",
    "        weights[0] = 1.0\n",
    "    else:\n",
    "        weights = [1.0 for i in range(num_known_classes)]\n",
    "elif dataset_name == 'GRSS':\n",
    "    weights = [1.0 for i in range(num_known_classes)]\n",
    "else:\n",
    "    weights = [1.0 for i in range(num_known_classes)]\n",
    "    if 4 not in hidden:\n",
    "        weights[-1] = 2.0\n",
    "\n",
    "global_weights = torch.FloatTensor(weights)\n",
    "\n",
    "# Setting experiment name.\n",
    "exp_name = conv_name + '_' + dataset_name + '_base_dsm_' + args['hidden_classes']\n",
    "\n",
    "# # Setting device [0|1|2].\n",
    "# args['device'] = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2e53105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function.\n",
    "def train(train_loader, net, criterion, optimizer, epoch, num_known_classes, num_unknown_classes, hidden, args):\n",
    "\n",
    "    # Setting network for training mode.\n",
    "    net.train()\n",
    "\n",
    "    # Average Meter for batch loss.\n",
    "    train_loss = list()\n",
    "\n",
    "    prds_all = []\n",
    "    labs_all = []\n",
    "\n",
    "    # Iterating over batches.\n",
    "    for i, data in enumerate(train_loader):\n",
    "        \n",
    "        inps, labs, true, img_name = None, None, None, None\n",
    "        \n",
    "        if dataset_name == 'GRSS':\n",
    "            \n",
    "            # Obtaining images and labels for batch.\n",
    "            inps, labs, true = data\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            # Obtaining images, labels and paths for batch.\n",
    "            inps, labs, true, img_name = data\n",
    "        \n",
    "        # Casting tensors to cuda.\n",
    "#         inps, labs, true = inps.cuda(), labs.cuda(), true.cuda()\n",
    "#         inps, labs, true = inps.cuda(args['device']), labs.cuda(args['device']), true.cuda(args['device'])\n",
    "        \n",
    "        # Casting to cuda variables.\n",
    "        inps = inps.cuda()#args['device'])\n",
    "        labs = labs.cuda()#args['device'])\n",
    "        true = true.cuda()#args['device'])\n",
    "        \n",
    "        if dataset_name == 'iSAID':\n",
    "            \n",
    "            inps = inps.view(inps.size(0) * inps.size(1), inps.size(2), inps.size(3), inps.size(4))\n",
    "            labs = labs.view(labs.size(0) * labs.size(1), labs.size(2), labs.size(3))\n",
    "            true = true.view(true.size(0) * true.size(1), true.size(2), true.size(3))\n",
    "            \n",
    "        else:\n",
    "            \n",
    "#             print('inps before', inps.size())\n",
    "#             print('labs before', labs.size())\n",
    "#             print('true before', true.size())\n",
    "#             sys.stdout.flush()\n",
    "            \n",
    "            inps.squeeze_(0)\n",
    "            labs.squeeze_(0)\n",
    "            true.squeeze_(0)\n",
    "            \n",
    "#             print('inps after', inps.size())\n",
    "#             print('labs after', labs.size())\n",
    "#             print('true after', true.size())\n",
    "#             sys.stdout.flush()\n",
    "        \n",
    "        # Clears the gradients of optimizer.\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forwarding.\n",
    "        outs = net(inps)\n",
    "        soft_outs = F.softmax(outs, dim=1)\n",
    "        \n",
    "        # Obtaining predictions.\n",
    "        prds = soft_outs.data.max(1)[1]\n",
    "        \n",
    "        # Computing loss.\n",
    "        loss = criterion(outs, labs)\n",
    "        \n",
    "        # Computing backpropagation.\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Appending images for epoch loss calculation.\n",
    "        prds = prds.squeeze_(1).squeeze_(0).cpu().numpy()\n",
    "        \n",
    "        inps_np = inps.detach().squeeze(0).cpu().numpy()\n",
    "        labs_np = labs.detach().squeeze(0).cpu().numpy()\n",
    "        true_np = true.detach().squeeze(0).cpu().numpy()\n",
    "\n",
    "        prds_all.append(prds)\n",
    "        labs_all.append(labs_np)\n",
    "        \n",
    "        # Updating loss meter.\n",
    "        train_loss.append(loss.data.item())\n",
    "        \n",
    "        # Printing.\n",
    "        #if (i + 1) % args['print_freq'] == 0:\n",
    "        #    print('[epoch %d], [iter %d / %d], [train loss %.5f]' % (epoch, i + 1, len(train_loader), np.asarray(train_loss).mean()))\n",
    "        #    sys.stdout.flush()\n",
    "    if epoch % args['print_freq'] == 0:\n",
    "        print(evaluate(prds_all, labs_all, num_known_classes))\n",
    "    \n",
    "    sys.stdout.flush()\n",
    "\n",
    "def test(test_loader, net, criterion, optimizer, epoch, num_known_classes, num_unknown_classes, hidden, args, save_images, save_model):\n",
    "    \n",
    "    if save_model:\n",
    "\n",
    "        torch.save(net.state_dict(), os.path.join(ckpt_path, exp_name, 'model_' + str(epoch) + '.pth'))\n",
    "        torch.save(optimizer.state_dict(), os.path.join(ckpt_path, exp_name, 'opt_' + str(epoch) + '.pth'))\n",
    "    \n",
    "    # Setting network for evaluation mode.\n",
    "    net.eval()\n",
    "    labs_all = []\n",
    "    prds_all = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # Creating output directory.\n",
    "        if save_images:\n",
    "            check_mkdir(os.path.join(outp_path, exp_name, 'validation', 'epoch_' + str(epoch)))\n",
    "        \n",
    "        # Iterating over batches.\n",
    "        for i, data in enumerate(test_loader):\n",
    "            \n",
    "            #print('Test Batch %d/%d' % (i + 1, len(test_loader)))\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            # Obtaining images, labels and paths for batch.\n",
    "            inps_batch, labs_batch, true_batch, img_name = data\n",
    "            \n",
    "            inps_batch = inps_batch.squeeze()\n",
    "            labs_batch = labs_batch.squeeze()\n",
    "            true_batch = true_batch.squeeze()\n",
    "            \n",
    "            # Iterating over patches inside batch.\n",
    "            for j in range(inps_batch.size(0)):\n",
    "                \n",
    "                #print('    Test MiniBatch %d/%d' % (j + 1, inps_batch.size(0)))\n",
    "                sys.stdout.flush()\n",
    "                \n",
    "                tic = time.time()\n",
    "                \n",
    "                for k in range(inps_batch.size(1)):\n",
    "                    \n",
    "                    inps = inps_batch[j, k].unsqueeze(0)\n",
    "                    labs = labs_batch[j, k].unsqueeze(0)\n",
    "                    true = true_batch[j, k].unsqueeze(0)\n",
    "                    \n",
    "                    # Casting tensors to cuda.\n",
    "#                     inps, labs, true = inps.cuda(args['device']), labs.cuda(args['device']), true.cuda(args['device'])\n",
    "                    \n",
    "                    # Casting to cuda variables.\n",
    "                    inps = inps.cuda()#args['device'])\n",
    "                    labs = labs.cuda()#args['device'])\n",
    "                    true = true.cuda()#args['device'])\n",
    "                    \n",
    "                    # Forwarding.\n",
    "                    if conv_name == 'unet' or conv_name == 'unet2':\n",
    "                        outs, dec1, dec2, dec3, dec4 = net(inps, feat=True)\n",
    "                    elif conv_name == 'fcnresnet50':\n",
    "                        outs, classif1, fv2 = net(inps, feat=True)\n",
    "                    elif conv_name == 'fcnresnext50':\n",
    "                        outs, classif1, fv2 = net(inps, feat=True)\n",
    "                    elif conv_name == 'fcnwideresnet50':\n",
    "                        outs, classif1, fv2 = net(inps, feat=True)\n",
    "                    elif conv_name == 'fcndensenet121':\n",
    "                        outs, classif1, fv2 = net(x=inps, feat=True)\n",
    "                    elif conv_name == 'fcndensenet121pretrained':\n",
    "                        outs, classif1, fv2 = net(inps, feat=True)\n",
    "                    elif conv_name == 'fcnvgg19':\n",
    "                        outs, classif1, fv3 = net(inps, feat=True)\n",
    "                    elif conv_name == 'fcnvgg19pretrained':\n",
    "                        outs, classif1, fv3 = net(inps, feat=True)\n",
    "                    elif conv_name == 'fcninceptionv3':\n",
    "                        outs, classif1, fv4 = net(inps, feat=True)\n",
    "                    elif conv_name == 'fcnmobilenetv2':\n",
    "                        outs, classif1, fv3 = net(inps, feat=True)\n",
    "                    elif conv_name == 'segnet':\n",
    "                        outs, x_10d, x_20d = net(inps, feat=True)\n",
    "                    \n",
    "                    # Computing probabilities.\n",
    "                    soft_outs = F.softmax(outs, dim=1)\n",
    "                    \n",
    "                    # Obtaining prior predictions.\n",
    "                    prds = soft_outs.data.max(1)[1]\n",
    "                    \n",
    "                    # Obtaining posterior predictions.\n",
    "                    if conv_name == 'unet' or conv_name == 'unet2':\n",
    "                        feat_flat = torch.cat([outs, dec1, dec2, dec3], 1)\n",
    "                    elif conv_name == 'fcnresnet50':\n",
    "                        feat_flat = torch.cat([outs, classif1, fv2], 1)\n",
    "                    elif conv_name == 'fcnresnext50':\n",
    "                        feat_flat = torch.cat([outs, classif1, fv2], 1)\n",
    "                    elif conv_name == 'fcnwideresnet50':\n",
    "                        feat_flat = torch.cat([outs, classif1, fv2], 1)\n",
    "                    elif conv_name == 'fcndensenet121':\n",
    "                        feat_flat = torch.cat([outs, classif1, fv2], 1)\n",
    "                    elif conv_name == 'fcndensenet121pretrained':\n",
    "                        feat_flat = torch.cat([outs, classif1, fv2], 1)\n",
    "                    elif conv_name == 'fcnvgg19':\n",
    "                        feat_flat = torch.cat([outs, classif1, fv3], 1)\n",
    "                    elif conv_name == 'fcnvgg19pretrained':\n",
    "                        feat_flat = torch.cat([outs, classif1, fv3], 1)\n",
    "                    elif conv_name == 'fcninceptionv3':\n",
    "                        feat_flat = torch.cat([outs, classif1, fv4], 1)\n",
    "                    elif conv_name == 'fcnmobilenetv2':\n",
    "                        feat_flat = torch.cat([outs, classif1, fv3], 1)\n",
    "                    elif conv_name == 'segnet':\n",
    "                        feat_flat = torch.cat([outs, x_10d, x_20d], 1)\n",
    "                    feat_flat = feat_flat.permute(0, 2, 3, 1).contiguous().view(feat_flat.size(0) * feat_flat.size(2) * feat_flat.size(3), feat_flat.size(1)).cpu().numpy()\n",
    "                    prds_flat = prds.cpu().numpy().ravel()\n",
    "                    true_flat = true.cpu().numpy().ravel()\n",
    "                    \n",
    "                    # Appending images for epoch loss calculation.\n",
    "                    inps_np = inps.detach().squeeze(0).cpu().numpy()\n",
    "                    labs_np = labs.detach().squeeze(0).cpu().numpy()\n",
    "                    true_np = true.detach().squeeze(0).cpu().numpy()\n",
    "\n",
    "                    prds = prds.cpu().squeeze().numpy()\n",
    "                    prds_all.append(prds)\n",
    "                    labs_all.append(labs_np)\n",
    "                    \n",
    "                    # Saving predictions.\n",
    "                    if (save_images):\n",
    "                        \n",
    "                        imag_path = os.path.join(outp_path, exp_name, 'validation', 'epoch_' + str(epoch), img_name[0].replace('.tif', '_img_' + str(j) + '_' + str(k) + '.png'))\n",
    "                        mask_path = os.path.join(outp_path, exp_name, 'validation', 'epoch_' + str(epoch), img_name[0].replace('.tif', '_msk_' + str(j) + '_' + str(k) + '.png'))\n",
    "                        true_path = os.path.join(outp_path, exp_name, 'validation', 'epoch_' + str(epoch), img_name[0].replace('.tif', '_tru_' + str(j) + '_' + str(k) + '.png'))\n",
    "                        pred_path = os.path.join(outp_path, exp_name, 'validation', 'epoch_' + str(epoch), img_name[0].replace('.tif', '_prd_' + str(j) + '_' + str(k) + '.png'))\n",
    "                        \n",
    "                        io.imsave(imag_path, util.img_as_ubyte(((np.transpose(inps_np, (1, 2, 0)) + 0.5) * 255).astype(int)))\n",
    "                        io.imsave(mask_path, util.img_as_ubyte(labs_np))\n",
    "                        io.imsave(true_path, util.img_as_ubyte(true_np))\n",
    "                        io.imsave(pred_path, util.img_as_ubyte(prds))\n",
    "                \n",
    "                toc = time.time()\n",
    "                #print('        Elapsed Time: %.2f' % (toc - tic))\n",
    "        \n",
    "        sys.stdout.flush()\n",
    "        print('#######################')\n",
    "        print('Test evaluation')\n",
    "        results = evaluate(prds_all, labs_all, num_known_classes)\n",
    "        print(results[:-1])\n",
    "        print('#######################')\n",
    "        return results[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d7258ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unet\n",
      "self.n_classes 4\n",
      "self.hidden_classes [0]\n",
      "self.n_classes 4\n",
      "self.hidden_classes [0]\n",
      "Epoch  1\n",
      "(0.570134372418266, 0.48920732061879857, 0.33335205273284535, array([0.5572341 , 0.34277792, 0.4035657 , 0.02983049]), 0.4373203948544799)\n",
      "#######################\n",
      "Test evaluation\n",
      "(0.5223507838141513, 0.5701997676628833, 0.2796065461732598, array([0.279873  , 0.27652125, 0.54394564, 0.01808629]))\n",
      "#######################\n",
      "New best IoU found:  0.2796065461732598\n",
      "Epoch  2\n",
      "(0.7157686422838635, 0.546820093459593, 0.4262437499528323, array([0.73607507, 0.44996797, 0.4855483 , 0.03338367]), 0.5732261160377429)\n",
      "#######################\n",
      "Test evaluation\n",
      "(0.7519596494992054, 0.657776038584521, 0.5080872273736017, array([0.80668025, 0.50643774, 0.60693295, 0.11229797]))\n",
      "#######################\n",
      "New best IoU found:  0.5080872273736017\n",
      "Epoch  3\n",
      "(0.7421290112984154, 0.6308882108551878, 0.48938725560020807, array([0.83931326, 0.46217732, 0.50139119, 0.15466725]), 0.6102264138120168)\n",
      "#######################\n",
      "Test evaluation\n",
      "(0.7460163694852762, 0.7409130516035689, 0.48493481486590323, array([0.7053892 , 0.51339837, 0.6259223 , 0.0950294 ]))\n",
      "#######################\n",
      "Previous best IoU 0.5080872273736017 at epoch 2\n",
      "Epoch  4\n",
      "(0.7459060837207806, 0.6504516381467058, 0.4987109347729556, array([0.77898425, 0.43406664, 0.52173316, 0.26005969]), 0.6033478038089045)\n",
      "#######################\n",
      "Test evaluation\n",
      "(0.6922784573217613, 0.742092638307427, 0.47642418587512364, array([0.84921136, 0.41775905, 0.61475614, 0.02397019]))\n",
      "#######################\n",
      "Previous best IoU 0.5080872273736017 at epoch 2\n",
      "Epoch  5\n",
      "(0.7591871444306025, 0.6447624029781538, 0.4907648229911069, array([0.75872948, 0.56165877, 0.53948807, 0.10318297]), 0.6247007528542837)\n",
      "#######################\n",
      "Test evaluation\n",
      "(0.7745067210620667, 0.774877848170536, 0.5125448322719354, array([0.73997891, 0.56142761, 0.68743629, 0.06133652]))\n",
      "#######################\n",
      "New best IoU found:  0.5125448322719354\n",
      "Epoch  6\n",
      "(0.7751682909126911, 0.6345465806768051, 0.5167591001745299, array([0.81979172, 0.51689921, 0.59884939, 0.13149608]), 0.646127308467738)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 68>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m train(train_loader, net, criterion, optimizer, epoch, num_known_classes, num_unknown_classes, hidden, args)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_freq\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     75\u001b[0m \n\u001b[1;32m     76\u001b[0m     \u001b[38;5;66;03m# Computing test.\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m     current_iou \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_known_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_unknown_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m current_iou \u001b[38;5;241m>\u001b[39m best_iou:\n\u001b[1;32m     79\u001b[0m         best_iou \u001b[38;5;241m=\u001b[39m current_iou\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(test_loader, net, criterion, optimizer, epoch, num_known_classes, num_unknown_classes, hidden, args, save_images, save_model)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m conv_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msegnet\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    203\u001b[0m     feat_flat \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([outs, x_10d, x_20d], \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 204\u001b[0m feat_flat \u001b[38;5;241m=\u001b[39m \u001b[43mfeat_flat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeat_flat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfeat_flat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfeat_flat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeat_flat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    205\u001b[0m prds_flat \u001b[38;5;241m=\u001b[39m prds\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mravel()\n\u001b[1;32m    206\u001b[0m true_flat \u001b[38;5;241m=\u001b[39m true\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mravel()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Setting network architecture.\n",
    "if (conv_name == 'unet'):\n",
    "\n",
    "    net = UNet(args['input_channels'], num_classes=args['num_classes'], hidden_classes=hidden).cuda()#args['device'])\n",
    "\n",
    "elif (conv_name == 'fcnwideresnet50'):\n",
    "\n",
    "    net = FCNWideResNet50(args['input_channels'], num_classes=args['num_classes'], pretrained=False, skip=True, hidden_classes=hidden).cuda()#args['device'])\n",
    "\n",
    "elif (conv_name == 'fcndensenet121'):\n",
    "\n",
    "    net = FCNDenseNet121(args['input_channels'], num_classes=args['num_classes'], pretrained=False, skip=True, hidden_classes=hidden).cuda()#args['device'])\n",
    "\n",
    "#net = nn.DataParallel(net)\n",
    "#print(net)\n",
    "print(conv_name)\n",
    "sys.stdout.flush()\n",
    "\n",
    "curr_epoch = 1\n",
    "args['best_record'] = {'epoch': 0, 'lr': 1e-4, 'val_loss': 1e10, 'acc': 0, 'acc_cls': 0, 'iou': 0}\n",
    "\n",
    "# Setting datasets.\n",
    "train_set = ListDataset(dataset_name, 'Train', (args['h_size'], args['w_size']), 'statistical', hidden, overlap=False, use_dsm=True, dataset_path='../datasets/')\n",
    "train_loader = DataLoader(train_set, batch_size=args['batch_size'], num_workers=args['num_workers'], shuffle=True)\n",
    "\n",
    "test_set = ListDataset(dataset_name, 'Validate', (args['h_size'], args['w_size']), 'statistical', hidden, overlap=True, use_dsm=True, dataset_path='../datasets/')\n",
    "test_loader = DataLoader(test_set, batch_size=1, num_workers=args['num_workers'], shuffle=False)\n",
    "\n",
    "# Setting criterion.\n",
    "#criterion = CrossEntropyLoss2d(weight=global_weights, size_average=False, ignore_index=args['num_classes']).cuda()#args['device'])\n",
    "criterion = CrossEntropyLoss2d(weight=global_weights, size_average=False, ignore_index=args['num_classes']-len(hidden)).cuda()#args['device'])\n",
    "\n",
    "# Setting optimizer.\n",
    "#     optimizer = optim.SGD(net.parameters(), lr=args['lr'], momentum=args['momentum'], weight_decay=args['weight_decay'])\n",
    "optimizer = optim.Adam([\n",
    "    {'params': [param for name, param in net.named_parameters() if name[-4:] == 'bias'],\n",
    "     'lr': 2 * args['lr']},\n",
    "    {'params': [param for name, param in net.named_parameters() if name[-4:] != 'bias'],\n",
    "     'lr': args['lr'], 'weight_decay': args['weight_decay']}\n",
    "], betas=(args['momentum'], 0.99))\n",
    "\n",
    "scheduler = None\n",
    "if dataset_name == 'GRSS':\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, args['epoch_num'] // 3, 0.2)\n",
    "elif dataset_name == 'iSAID':\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, args['epoch_num'] // 5, 0.2)\n",
    "else:\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, args['epoch_num'] // 3, 0.2)\n",
    "\n",
    "# Making sure checkpoint and output directories are created.\n",
    "check_mkdir(ckpt_path)\n",
    "check_mkdir(os.path.join(ckpt_path, exp_name))\n",
    "check_mkdir(outp_path)\n",
    "check_mkdir(os.path.join(outp_path, exp_name))\n",
    "\n",
    "# Writing training args to experiment log file.\n",
    "open(os.path.join(ckpt_path, exp_name, str(datetime.datetime.now()) + '.txt'), 'w').write(str(args) + '\\n\\n')\n",
    "\n",
    "\n",
    "best_model = copy.deepcopy(net)\n",
    "best_iou = -1\n",
    "best_epoch = 0\n",
    "# Iterating over epochs.\n",
    "for epoch in range(curr_epoch, args['epoch_num'] + 1):\n",
    "\n",
    "    # Training function.\n",
    "    print('Epoch ',epoch)\n",
    "    train(train_loader, net, criterion, optimizer, epoch, num_known_classes, num_unknown_classes, hidden, args)\n",
    "\n",
    "    if epoch % args['test_freq'] == 0:\n",
    "\n",
    "        # Computing test.\n",
    "        current_iou = test(test_loader, net, criterion, optimizer, epoch, num_known_classes, num_unknown_classes, hidden, args, False, False)\n",
    "        if current_iou > best_iou:\n",
    "            best_iou = current_iou\n",
    "            best_model = copy.deepcopy(net)\n",
    "            best_epoch = epoch\n",
    "            print('New best IoU found: ', current_iou)\n",
    "        else:\n",
    "            print('Previous best IoU {0} at epoch {1}'.format(best_iou, best_epoch))\n",
    "\n",
    "    scheduler.step()\n",
    "print('Final test')\n",
    "test(test_loader, best_model, criterion, optimizer, args['epoch_num'], num_known_classes, num_unknown_classes, hidden, args, False, True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
